import torch
import spaces
import gradio as gr
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    pipeline,
    TextIteratorStreamer,
)
from threading import Thread

tokenizer = AutoTokenizer.from_pretrained(
    "meta-llama/Llama-3.1-8B-Instruct",
)
if tokenizer.pad_token_id is None:
    tokenizer.pad_token_id = tokenizer.eos_token_id

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-3.1-8B-Instruct",
).to(device)

system_prompt = """
You are an expert editorial AI that revises text exclusively by converting genuinely passive constructions to active voiceâ€”only if it clearly improves the text. Do not correct typos, rephrase for brevity, or make any other editorial changes. Preserve the userâ€™s original meaning, tone, and paragraph structure.

âœ¨ Definitions & Core Instructions:
1ï¸âƒ£ Passive Voice Identification:
   â€¢ Passive constructions typically involve a form of â€œto beâ€ plus a past participle (e.g., â€œwas written by,â€ â€œis done byâ€).
   â€¢ If the agent (person/thing performing the action) is unknown or unimportant, or if converting it reduces clarity, leave it in passive form.
2ï¸âƒ£ Conversion Criteria:
   â€¢ Change a passive sentence to active voice only when it enhances clarity, flow, or directness.
   â€¢ If in doubt, do not convert.
3ï¸âƒ£ Output Format:
   â€¢ Return two sections:
       a) The fully revised text with paragraph breaks intact.
       b) A concise, numbered list of explanations for each converted sentence.

âœ¨ Multi-Paragraph Example:

â€¢ Input:
    "Several errors were noted by the review panel in the first chapter. 
     A set of findings was also documented in the appendix. 
     However, it was concluded that overall, the paper was thorough."

â€¢ Revised Text:
    "The review panel noted several errors in the first chapter. 
     The appendix also documented a set of findings. 
     However, it was concluded that overall, the paper was thorough."

â€¢ Explanations:
    1. Converted "Several errors were noted by the review panel" â†’ "The review panel noted several errors" 
       for clarity and directness.
    2. Converted "A set of findings was also documented" â†’ "The appendix also documented a set of findings" 
       to specify the agent clearly.
    3. Left "it was concluded that overall, the paper was thorough" unchanged because the agent is not specified 
       and converting might not improve readability.

âœ¨ Edge Cases:
â€¢ If a sentence seems passive but does not impede clarity or deliberately omits the agent, leave it as is.
â€¢ Avoid â€œfalse positivesâ€ where â€œwasâ€ or â€œisâ€ is simply describing a state of being (e.g., â€œThe experience was unique.â€).

Your mission:
1. Carefully evaluate multi-paragraph user input for genuine passive voice.
2. Make passive-to-active changes only when beneficial.
3. Return the revised text in its entirety, followed by explanations of each change.
"""


def clean_response(response: str) -> str:
    """
    Removes 'assistant\n\n' from the start of the response if it exists.
    """
    return (
        response.lstrip("assistant\n\n")
        if response.startswith("assistant\n\n")
        else response
    )


def user_prompt_for(text: str):
    return f"Please analyze this writing and return passive voice sentences corrected to active voice:\n{text}"


@spaces.GPU
def on_text_submitted(message: str):
    conversation = [{"role": "system", "content": system_prompt}]
    conversation.append({"role": "user", "content": user_prompt_for(message)})

    inputs = tokenizer.apply_chat_template(conversation, return_tensors="pt").to(device)

    streamer = TextIteratorStreamer(
        tokenizer, timeout=60.0, skip_prompt=True, skip_special_tokens=True
    )

    generate_kwargs = dict(input_ids=inputs, max_new_tokens=3000, streamer=streamer)

    response_buffer = ""

    with torch.no_grad():
        thread = Thread(target=model.generate, kwargs=generate_kwargs)
        thread.start()

        for chunk in streamer:
            response_buffer += chunk
            formatted_response_buffer = clean_response(response_buffer)

            yield formatted_response_buffer


with gr.Blocks() as demo:
    gr.Markdown(
        """
      ## âœ¨ Active Voiceifyer âœ¨
      
      Identifies passive sentences in your text and rewrites them in a dynamic, active voice.
      
      Powered by Meta Llama3 8B.
      """
    )

    with gr.Row():
        input_text = gr.Textbox(
            label="âœï¸ Enter your writing below:",
            lines=10,
            placeholder="Enter text here...",
        )
        output_text = gr.Markdown(label="ğŸ¤– Response:")
    with gr.Row():
        clear_button = gr.Button("ğŸ—‘ï¸ Clear")
        submit_button = gr.Button("ğŸ“© Send")

    submit_button.click(
        on_text_submitted,
        inputs=[input_text],
        outputs=[output_text],
    )
    clear_button.click(lambda: ("", ""), inputs=[], outputs=[input_text, output_text])

demo.launch(server_name="0.0.0.0", server_port=7860)
